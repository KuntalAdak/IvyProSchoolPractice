{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#   <font color='Brown'> Working with Text Data\n",
        "    \n",
        "#### <font color='Blue'> Topics Covered:\n",
        "\n",
        "\n",
        "\n",
        "1.   **Text cleaning**: Understanding principles of Regex Patterns\n",
        "2.   **Tokenization**: Using specific NLP Libarary creating tokens\n",
        "3.   **Lemmatization**: Understanding & applying Lemmatization\n",
        "4.   **Stop Words**: Understanding what are stop words & removal of them\n",
        "5.   **TF-IDF Vectorizer**: Using TF-IDF Vectorizer, understanding feature importance of variables\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<span style='color:Orange'> - Arpendu Ganguly</span>"
      ],
      "metadata": {
        "id": "DNv8Qk_ZcOpq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://miro.medium.com/v2/resize:fit:1024/1*vXKKe3J-lfi1YQ7HC6onxQ.jpeg)"
      ],
      "metadata": {
        "id": "bODjN-oYd5DE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What are Regular Expressions?\n",
        "\n",
        "**Regular expressions or RegEx** is defined as a sequence of characters that are mainly used to find or replace patterns present in the text.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Extracting all hashtags from a tweet, getting email iD or phone numbers, etc from large unstructured text content are some examples of Regular Expressions\n",
        "\n"
      ],
      "metadata": {
        "id": "bEH-HpnZp2Xk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### I. Common Regex Functions used in NLP\n",
        "\n",
        "Python has a built-in module known as “re” for Regular Expressions. Some common functions from this module are as follows:\n",
        "\n",
        "*   **re.search()**:Take the pattern, scan the text, and then return a Match object.\n",
        "*   **re.match()**:match the string if the pattern is present at start of string\n",
        "*   **re.sub()**:Replaces one or many matches with a string\n",
        "*   **re.compile()**:stores the pattern in the cache memory for faster searches\n",
        "*   **re.findall()**:Returns a list containing all matches\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2419ulUXrVdt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FxR7_t5nX0kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#re.search( ):\n",
        "#given regular expression pattern is present in the given input string. It matches the first occurrence of a pattern in the entire string and not just at the beginning\n",
        "\n",
        "#Syntax: re.search(patterns, string)\n",
        "#‘re.I’ — to ignore the case (either uppercase or lowercase) of the text\n",
        "#'re.M' — enables to search the string in multiple lines\n",
        "#re.search(pattern, string, flags=re.I | re.M)\n",
        "\n",
        "#Example1\n",
        "import re\n",
        "text_1 = \"Ivy offers multiple Data Science Modules.Ivy also offers Data Engineering modules\"\n",
        "result_1 = re.search(r\"Ivy\",text_1)\n",
        "print(\"with matching case:\",result_1.group())\n",
        "\n",
        "#Example2\n",
        "import re\n",
        "text_2 = \"Ivy offers multiple Data Science Modules\"\n",
        "result_2 = re.search(r\"ivy\",text_2,flags=re.I)\n",
        "print(\"without matching case:\",result_2.group())\n",
        "\n",
        "\n",
        "#Example3\n",
        "import re\n",
        "text_3 = \"There is a lot of potential in Data Science\"\n",
        "result_3 = re.search(r\"Ivy\",text_3,flags=re.I)\n",
        "print(\"with no match here:\",result_3)\n"
      ],
      "metadata": {
        "id": "pfb_DgejdkWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "736ad910-eceb-4bd8-dbcf-599f9f3f27c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "with matching case: Ivy\n",
            "without matching case: Ivy\n",
            "with no match here: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#re.match( )\n",
        "#This function will only match the string if the pattern is present at the very start of the string.\n",
        "\n",
        "#Syntax: re.match(patterns, string)\n",
        "import re\n",
        "text_2 = \"Ivy offers multiple Data Science Modules\"\n",
        "result_2 = re.match(r\"Ivy\",text_2)\n",
        "print(\"Match Output:\",result_2.group())\n",
        "\n",
        "#Syntax: re.match(patterns, string)\n",
        "import re\n",
        "text_2 = \"It offers multiple Data Science Modules.Ivy is Good\"\n",
        "result_2 = re.match(r\"Ivy\",text_2)\n",
        "print(\"Match Output:\",result_2)\n",
        "\n"
      ],
      "metadata": {
        "id": "DYN4FMj9oSmp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "658b7e8e-6c94-4618-a8f2-b8843e68e08c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Match Output: Ivy\n",
            "Match Output: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#re.sub( ):\n",
        "#given used to substitute a substring with another substring\n",
        "#Syntax: re.sub(patterns, Substitute, Input text)\n",
        "\n",
        "#Example1\n",
        "import re\n",
        "text_1 = \"I love R in Data Science Programming. SPSS is verstaile\"\n",
        "result_1 = re.sub(r\"R|SPSS\",\"Python\",text_1)\n",
        "print(\"old text:\",text_1)\n",
        "print(\"new text:\",result_1)"
      ],
      "metadata": {
        "id": "BWNJ129ArplE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61163265-1ea7-441c-bc78-30a7551e66ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "old text: I love R in Data Science Programming. SPSS is verstaile\n",
            "new text: I love Python in Data Science Programming. Python is verstaile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#re.compile( )\n",
        "#It stores the regular expression pattern in the cache memory for faster searches. So, we have to pass the regex pattern to re.compile() function.\n",
        "#Syntax: re.compile(patterns, repl, string)\n",
        "\n",
        "#Example1\n",
        "import re\n",
        "text_1 = re.compile(\"Ivy\")\n",
        "result_1 = text_1.findall(\"Ivy offers Data Science Course. Lot of students are prospering with Ivy\")\n",
        "result_2 = text_1.findall(\"NLP courses are Good in Ivy\")\n",
        "print(\"1st instance:\",result_1)\n",
        "print(\"2nd instance:\",result_2)"
      ],
      "metadata": {
        "id": "pSGCm98owS6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac6a6e57-41ac-4d9e-eb13-402b3b4622ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1st instance: ['Ivy', 'Ivy']\n",
            "2nd instance: ['Ivy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#re.findall( )\n",
        "#will return all the occurrences of the pattern from the string\n",
        "#Syntax: re.findall(patterns, string)\n",
        "\n",
        "#Example1\n",
        "import re\n",
        "\n",
        "result_1 = re.findall(\"Deep Learning\",\"Deep Learning is a emerging field. There are various sub-fields in Deep Learning\")\n",
        "print(\"Find All Results Given:\",result_1)"
      ],
      "metadata": {
        "id": "k5grL6eByNFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a0a4d96-e3b5-4417-95e8-efdfa711e278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Find All Results Given: ['Deep Learning', 'Deep Learning']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#re.split( )\n",
        "#returns a list where the string has been split at each match.\n",
        "#Syntax: re.split(splitterm, phrase)\n",
        "\n",
        "#Example1\n",
        "import re\n",
        "\n",
        "split_term = '@'\n",
        "phrase = 'My email is my_first_name@gmail.com'\n",
        "\n",
        "result_1 = re.split(split_term,phrase)\n",
        "print(\"Split Results Given:\",result_1)"
      ],
      "metadata": {
        "id": "QdnyS4i5pQQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6414befc-fde3-4db8-d911-22db48890337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split Results Given: ['My email is my_first_name', 'gmail.com']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### II. Special Characters in Regex\n",
        "\n",
        "\n",
        "\n",
        "**Metacharacters**\n",
        "There are five ways to express repetition in a pattern:\n",
        "\n",
        "\n",
        "\n",
        "1.   A pattern followed by the meta-character * is repeated zero or more times.\n",
        "2.   Replace the * with + and the pattern must appear at least once.\n",
        "3.   Using ? means the pattern appears zero or one time.\n",
        "4.   For a specific number of occurrences, use {n} after the pattern, where n\n",
        "     is replaced with the number of times the pattern should repeat.\n",
        "4.   Use {x,y} where x is the minimum number of repetitions and y is the maximum.\n",
        "2.   Leaving out y {x,} means the value appears at least x times, with no maximum.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WozTRK0azjm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_re_find(patterns,phrase):\n",
        "    '''\n",
        "    Takes in a list of regex patterns\n",
        "    Prints a list of all matches\n",
        "    '''\n",
        "    for i in range(0,len(patterns)):\n",
        "        print(\"Searching the phrase using the re check:\",patterns[i])\n",
        "        print(re.findall(patterns[i],phrase))\n",
        "        print('\\n')"
      ],
      "metadata": {
        "id": "SYyQx3E7x7h1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_phrase = 'gaga....gggaaa...gaaagaaa...agga...agggg...agggg'\n",
        "\n",
        "#test_pattern = 'ga*'\n",
        "\n",
        "test_pattern = ['ga*',#g is followed by zero or more a's\n",
        "                'ga+',#g is followed by one or more a's\n",
        "                'ga?',#g is followed by zero or one a's\n",
        "                'ga{3}',#g is followed by three a's\n",
        "                'ga{1,3}'#g is followed by one to three a's\n",
        "                 ]\n",
        "\n",
        "multi_re_find(test_pattern,test_phrase)"
      ],
      "metadata": {
        "id": "QbumPdy0rC2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1527df23-55be-4547-f20f-c8568993ead9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching the phrase using the re check: ga*\n",
            "['ga', 'ga', 'g', 'g', 'gaaa', 'gaaa', 'gaaa', 'ga', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g']\n",
            "\n",
            "\n",
            "Searching the phrase using the re check: ga+\n",
            "['ga', 'ga', 'gaaa', 'gaaa', 'gaaa', 'ga']\n",
            "\n",
            "\n",
            "Searching the phrase using the re check: ga?\n",
            "['ga', 'ga', 'g', 'g', 'ga', 'ga', 'ga', 'ga', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g']\n",
            "\n",
            "\n",
            "Searching the phrase using the re check: ga{3}\n",
            "['gaaa', 'gaaa', 'gaaa']\n",
            "\n",
            "\n",
            "Searching the phrase using the re check: ga{1,3}\n",
            "['ga', 'ga', 'gaaa', 'gaaa', 'gaaa', 'ga']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### II. Special Characters in Regex\n",
        "\n",
        "\n",
        "\n",
        "**Special Sequences**\n",
        "Special sequence or escape codes to find specific types of patterns in your data, such as digits, non-digits, whitespace.Escapes are indicated by prefixing the character with a backslash \\.\n",
        "\n",
        "\n",
        "\n",
        "Character--Description--Example Pattern Code--Example Match\n",
        "\n",
        "\n",
        "*   \\d\tA digit\tfile_\\d\\d\tfile_25\n",
        "*   \\D\tA non digit\t\\D\\D\\D\tABC\n",
        "*   \\w\tAlphanumeric\t\\w-\\w\\w\\w\tA-b_1\n",
        "*   \\W\tNon-alphanumeric\t\\W\\W\\W\\W\t!*+)\n",
        "*   \\s\tWhite space\ta\\sb\\sc\ta b c\n",
        "*  \\S\tNon-whitespace\t\\S\\S\\S\\S\tThis\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qYavII5KujU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Jersey number of MS Dhoni is 7, his twitter account is @MSDhoni. '\n",
        "\n",
        "patterns=[ r'\\d+', # sequence of digits\n",
        "           r'\\D+', # sequence of non-digits\n",
        "           r'\\s+', # sequence of whitespace\n",
        "           r'\\S+', # sequence of non-whitespace\n",
        "           r'\\w+', # alphanumeric characters\n",
        "           r'\\W+', # non-alphanumeric\n",
        "          ]\n",
        "\n",
        "multi_re_find(patterns,text)"
      ],
      "metadata": {
        "id": "XpeE0sTntthB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "897f9b91-f4a9-45a8-81dd-5357a4923b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching the phrase using the re check: \\d+\n",
            "['7']\n",
            "\n",
            "\n",
            "Searching the phrase using the re check: \\D+\n",
            "['Jersey number of MS Dhoni is ', ', his twitter account is @MSDhoni. ']\n",
            "\n",
            "\n",
            "Searching the phrase using the re check: \\s+\n",
            "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n",
            "\n",
            "\n",
            "Searching the phrase using the re check: \\S+\n",
            "['Jersey', 'number', 'of', 'MS', 'Dhoni', 'is', '7,', 'his', 'twitter', 'account', 'is', '@MSDhoni.']\n",
            "\n",
            "\n",
            "Searching the phrase using the re check: \\w+\n",
            "['Jersey', 'number', 'of', 'MS', 'Dhoni', 'is', '7', 'his', 'twitter', 'account', 'is', 'MSDhoni']\n",
            "\n",
            "\n",
            "Searching the phrase using the re check: \\W+\n",
            "[' ', ' ', ' ', ' ', ' ', ' ', ', ', ' ', ' ', ' ', ' @', '. ']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### III. Character Sets in Regex\n",
        "\n",
        "\n",
        "\n",
        "**Character Sets**\n",
        "Character sets are used when you wish to match any one of a group of characters at a point in the input. Brackets are used to construct character set inputs.\n",
        "\n",
        "For example, the input [ab] searches for occurrences of either a or b.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5410rM61wDyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_phrase = 'gaga....gggaaa...gaaagaaa...agag...agggg...agggg'\n",
        "\n",
        "#test_pattern = 'ga*'\n",
        "\n",
        "test_pattern = ['[ga]',#either g or a\n",
        "                'g[ga]+',#g is followed by one or more g or a\n",
        "                 ]\n",
        "\n",
        "multi_re_find(test_pattern,test_phrase)"
      ],
      "metadata": {
        "id": "ZFQYEDksvkRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2172cdb0-ac7c-45ea-fd0c-bfffcf025392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching the phrase using the re check: [ga]\n",
            "['g', 'a', 'g', 'a', 'g', 'g', 'g', 'a', 'a', 'a', 'g', 'a', 'a', 'a', 'g', 'a', 'a', 'a', 'a', 'g', 'a', 'g', 'a', 'g', 'g', 'g', 'g', 'a', 'g', 'g', 'g', 'g']\n",
            "\n",
            "\n",
            "Searching the phrase using the re check: g[ga]+\n",
            "['gaga', 'gggaaa', 'gaaagaaa', 'gag', 'gggg', 'gggg']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IV. Exclusions Regex\n",
        "\n",
        "\n",
        "\n",
        "**Exclusions**\n",
        " ^ is used to exclude terms by incorporating it into the bracket syntax notation.  \n",
        "\n",
        " [^!.? ] to check for matches that are not a !,.,?, or space.\n",
        "\n",
        "Add a + to check that the match appears at least once. This basically translates into finding the words."
      ],
      "metadata": {
        "id": "gTd4Ey_ww2iS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What is the jersey number of Christano Ronaldo?? Is it 7 or 9!\"\n",
        "re.findall('[^!.? ]+',text)"
      ],
      "metadata": {
        "id": "4xf1C2w-wm_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9480a6c3-92c3-4f65-ccec-db54794dbded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What',\n",
              " 'is',\n",
              " 'the',\n",
              " 'jersey',\n",
              " 'number',\n",
              " 'of',\n",
              " 'Christano',\n",
              " 'Ronaldo',\n",
              " 'Is',\n",
              " 'it',\n",
              " '7',\n",
              " 'or',\n",
              " '9']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IV. Character Ranges in Regex\n",
        "\n",
        "\n",
        "\n",
        "**Character Ranges**\n",
        "character ranges lets you define a character set to include all of the contiguous characters between a start and stop point. The format used is [start-end].\n",
        "\n",
        "For example, [a-g] will return matches between a and g"
      ],
      "metadata": {
        "id": "ryIyOXDpy3C1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_phrase = 'It was 7 in Manchester United, he was given that number right after Beckham left.'\n",
        "\n",
        "test_patterns=['[a-z]+',      # sequences of lower case letters\n",
        "               '[A-Z]+',      # sequences of upper case letters\n",
        "               '[a-zA-Z]+',   # sequences of lower or upper case letters\n",
        "               '[A-Z][a-z]+', # one upper case letter followed by lower case letters\n",
        "               '[0-9]+'       # sequences of digits\n",
        "              ]\n",
        "\n",
        "\n",
        "multi_re_find(test_patterns,test_phrase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H6ShoQCywt9",
        "outputId": "dc221d1f-2a2b-462a-cb86-1d6f54da2799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching the phrase using the re check: [a-z]+\n",
            "['t', 'was', 'in', 'anchester', 'nited', 'he', 'was', 'given', 'that', 'number', 'right', 'after', 'eckham', 'left']\n",
            "\n",
            "\n",
            "Searching the phrase using the re check: [A-Z]+\n",
            "['I', 'M', 'U', 'B']\n",
            "\n",
            "\n",
            "Searching the phrase using the re check: [a-zA-Z]+\n",
            "['It', 'was', 'in', 'Manchester', 'United', 'he', 'was', 'given', 'that', 'number', 'right', 'after', 'Beckham', 'left']\n",
            "\n",
            "\n",
            "Searching the phrase using the re check: [A-Z][a-z]+\n",
            "['It', 'Manchester', 'United', 'Beckham']\n",
            "\n",
            "\n",
            "Searching the phrase using the re check: [0-9]+\n",
            "['7']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VI. Tokenization\n",
        "\n",
        "\n",
        "\n",
        "Tokenization is essentially splitting a phrase, sentence, paragraph, or an entire text document into smaller units, such as individual words or terms. Each of these smaller units are called tokens."
      ],
      "metadata": {
        "id": "M-WXkkFmznjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --user -U nltk"
      ],
      "metadata": {
        "id": "tTV15Z6qzm6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f2fccfc-d3df-4649-d9e3-7187079a135a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet\n",
        "species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed\n",
        "liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
        "print(word_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtoP65E-0cOz",
        "outputId": "a6128acb-6980-458d-a497-1317b259a4f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Founded', 'in', '2002', ',', 'SpaceX', '’', 's', 'mission', 'is', 'to', 'enable', 'humans', 'to', 'become', 'a', 'spacefaring', 'civilization', 'and', 'a', 'multi-planet', 'species', 'by', 'building', 'a', 'self-sustaining', 'city', 'on', 'Mars', '.', 'In', '2008', ',', 'SpaceX', '’', 's', 'Falcon', '1', 'became', 'the', 'first', 'privately', 'developed', 'liquid-fuel', 'launch', 'vehicle', 'to', 'orbit', 'the', 'Earth', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VII. Lemmitization\n",
        "\n",
        "\n",
        "\n",
        "Lemmatization is another technique used to reduce inflected words to their root word. It describes the algorithmic process of identifying an inflected word’s “lemma” (dictionary form) based on its intended meaning.\n",
        "\n",
        "As opposed to stemming, lemmatization relies on accurately determining the intended part-of-speech and the meaning of a word based on its context."
      ],
      "metadata": {
        "id": "IDW0AVFm0t5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   I like **playing**\n",
        "*   I will **play** tomorrow\n",
        "*   Everyone **played** at at the school\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kNCinygOlecc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "# Initialize wordnet lemmatizer\n",
        "wnl = WordNetLemmatizer()\n",
        "example_words = [\"program\",\"programming\",\"programer\",\"programs\",\"programmed\"]\n",
        "print(\"{0:20}{1:20}\".format(\"--Word--\",\"--Lemma--\"))\n",
        "for word in example_words:\n",
        "   print (\"{0:20}{1:20}\".format(word, wnl.lemmatize(word,pos=\"v\")))\n",
        "\n",
        "# pos\n",
        "# \"n\" - nouns\n",
        "# \"v\" - verbs\n",
        "# \"a\" - adjectives\n",
        "# \"r\" - adverbs\n",
        "# \"s\" - satellite adjectives"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQd24QhFz-Aa",
        "outputId": "0a7d1506-785e-4ba3-dda8-9f27993f8de7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--Word--            --Lemma--           \n",
            "program             program             \n",
            "programming         program             \n",
            "programer           programer           \n",
            "programs            program             \n",
            "programmed          program             \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VIII. Stop Words\n",
        "\n",
        "\n",
        "\n",
        "Stop Words: A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query."
      ],
      "metadata": {
        "id": "xT4HUPQD1qkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INCJQuiw1KME",
        "outputId": "75739358-4e3f-41e0-ab55-03f7558910d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "example_sent = \"\"\"This is a sample sentence,\n",
        "                  showing off the stop words filtration.\"\"\"\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "new_stop_words = ['sample']\n",
        "stop_words.extend(new_stop_words)\n",
        "stop_words = set(stop_words)\n",
        "\n",
        "word_tokens = word_tokenize(example_sent)\n",
        "# converts the words in word_tokens to lower case and then checks whether\n",
        "#they are present in stop_words or not\n",
        "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "#with no lower case conversion\n",
        "filtered_sentence = []\n",
        "\n",
        "for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "        filtered_sentence.append(w)\n",
        "\n",
        "print(word_tokens)\n",
        "print(filtered_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry9033dl2B22",
        "outputId": "90340a09-5bed-4187-f5ee-c2f224ab482f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']\n",
            "['This', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words('english')\n",
        "new_stop_words = ['sample']\n",
        "stop_words.extend(new_stop_words)\n",
        "stop_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP41YkPxqkMm",
        "outputId": "c0ff2a5c-3dfd-4d6f-cdda-d751422fd231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'sample']"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IX. Term Frequency – Inverse Document Frequency (TF-IDF)\n",
        "\n",
        "Term Frequency – Inverse Document Frequency (TF-IDF) is a popular statistical technique utilized in natural language processing and information retrieval to assess a term’s significance in a document in comparison to a group of documents, known as a corpus. The technique employs a text vectorization process to transform words in a text document into numerical values that denote their importance.\n",
        "\n",
        "Term Frequency: TF of a term or word is the number of times the term appears in a document compared to the total number of words in the document.\n",
        "\n",
        "TF = {number of times the term appears in the document\\total number of terms in the document}\n",
        "\n",
        "Inverse Document Frequency: IDF of a term reflects the proportion of documents in the corpus that contain the term. Words unique to a small percentage of documents (e.g., technical jargon terms) receive higher importance values than words common across all documents (e.g., a, the, and).\n",
        "\n",
        "IDF = log ({total number of the documents in the corpus\\number of documents in the corpus contain the term})\n",
        "\n",
        "The TF-IDF of a term is calculated by multiplying TF and IDF scores."
      ],
      "metadata": {
        "id": "C3Df0SdI2tdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "eo0v_Z9l2HbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = ['data science is one of the most important fields of science',\n",
        "          'this is one of the best data science courses',\n",
        "          'data scientists analyze data' ]"
      ],
      "metadata": {
        "id": "hTJfvIyM3bPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_set = set()\n",
        "\n",
        "for doc in  corpus:\n",
        "    words = doc.split(' ')\n",
        "    words_set = words_set.union(set(words))\n",
        "\n",
        "print('Number of words in the corpus:',len(words_set))\n",
        "print('The words in the corpus: \\n', words_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Gq2S92u3bkc",
        "outputId": "1b3f4ded-a303-44be-c7af-01f8dd0f760c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in the corpus: 14\n",
            "The words in the corpus: \n",
            " {'courses', 'one', 'important', 'of', 'scientists', 'the', 'analyze', 'best', 'science', 'data', 'most', 'fields', 'this', 'is'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_idf_model  = TfidfVectorizer()\n",
        "tf_idf_vector = tr_idf_model.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "6qPGRIhd3ePA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(tf_idf_vector), tf_idf_vector.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3PVieOj3mD1",
        "outputId": "49c5e145-c4a8-4674-c967-ab23683f546c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'> (3, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_idf_array = tf_idf_vector.toarray()\n",
        "print(tf_idf_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqsC82q13qKQ",
        "outputId": "45a9c1ea-7fc7-45bf-fdc3-a529a1236a95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         0.18952581 0.32089509 0.32089509\n",
            "  0.24404899 0.32089509 0.48809797 0.24404899 0.48809797 0.\n",
            "  0.24404899 0.        ]\n",
            " [0.         0.40029393 0.40029393 0.23642005 0.         0.\n",
            "  0.30443385 0.         0.30443385 0.30443385 0.30443385 0.\n",
            "  0.30443385 0.40029393]\n",
            " [0.54270061 0.         0.         0.64105545 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.54270061\n",
            "  0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_set = tr_idf_model.get_feature_names_out()\n",
        "print(words_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxQDZFod3t9n",
        "outputId": "577de798-e477-4834-d2a6-37e1e786bc31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['analyze' 'best' 'courses' 'data' 'fields' 'important' 'is' 'most' 'of'\n",
            " 'one' 'science' 'scientists' 'the' 'this']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tf_idf = pd.DataFrame(tf_idf_array, columns = words_set)\n",
        "df_tf_idf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "qqpOE2fo3yE0",
        "outputId": "8a908310-4688-48b4-a6aa-074432f878cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    analyze      best   courses      data    fields  important        is  \\\n",
              "0  0.000000  0.000000  0.000000  0.189526  0.320895   0.320895  0.244049   \n",
              "1  0.000000  0.400294  0.400294  0.236420  0.000000   0.000000  0.304434   \n",
              "2  0.542701  0.000000  0.000000  0.641055  0.000000   0.000000  0.000000   \n",
              "\n",
              "       most        of       one   science  scientists       the      this  \n",
              "0  0.320895  0.488098  0.244049  0.488098    0.000000  0.244049  0.000000  \n",
              "1  0.000000  0.304434  0.304434  0.304434    0.000000  0.304434  0.400294  \n",
              "2  0.000000  0.000000  0.000000  0.000000    0.542701  0.000000  0.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01a06d64-29b3-4a36-9362-1a807305f84c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>analyze</th>\n",
              "      <th>best</th>\n",
              "      <th>courses</th>\n",
              "      <th>data</th>\n",
              "      <th>fields</th>\n",
              "      <th>important</th>\n",
              "      <th>is</th>\n",
              "      <th>most</th>\n",
              "      <th>of</th>\n",
              "      <th>one</th>\n",
              "      <th>science</th>\n",
              "      <th>scientists</th>\n",
              "      <th>the</th>\n",
              "      <th>this</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.189526</td>\n",
              "      <td>0.320895</td>\n",
              "      <td>0.320895</td>\n",
              "      <td>0.244049</td>\n",
              "      <td>0.320895</td>\n",
              "      <td>0.488098</td>\n",
              "      <td>0.244049</td>\n",
              "      <td>0.488098</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.244049</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.400294</td>\n",
              "      <td>0.400294</td>\n",
              "      <td>0.236420</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.304434</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.304434</td>\n",
              "      <td>0.304434</td>\n",
              "      <td>0.304434</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.304434</td>\n",
              "      <td>0.400294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.542701</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.641055</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.542701</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01a06d64-29b3-4a36-9362-1a807305f84c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-01a06d64-29b3-4a36-9362-1a807305f84c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-01a06d64-29b3-4a36-9362-1a807305f84c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2e543d8d-64fd-4dd3-9417-4c8b5295896a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e543d8d-64fd-4dd3-9417-4c8b5295896a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2e543d8d-64fd-4dd3-9417-4c8b5295896a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3a985d6e-9335-418b-aa4f-58b6bec22aed\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_tf_idf')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3a985d6e-9335-418b-aa4f-58b6bec22aed button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_tf_idf');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_tf_idf",
              "summary": "{\n  \"name\": \"df_tf_idf\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"analyze\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3133283451066585,\n        \"min\": 0.0,\n        \"max\": 0.5427006131762078,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5427006131762078,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2311098107948397,\n        \"min\": 0.0,\n        \"max\": 0.40029393442429256,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.40029393442429256,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"courses\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2311098107948397,\n        \"min\": 0.0,\n        \"max\": 0.40029393442429256,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.40029393442429256,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24826326557890868,\n        \"min\": 0.18952580966166682,\n        \"max\": 0.6410554491745127,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.18952580966166682,\n          0.2364200460658773\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fields\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18526886675016388,\n        \"min\": 0.0,\n        \"max\": 0.32089509027199203,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          0.32089509027199203\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"important\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18526886675016388,\n        \"min\": 0.0,\n        \"max\": 0.32089509027199203,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          0.32089509027199203\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16118633754253953,\n        \"min\": 0.0,\n        \"max\": 0.30443385488725433,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.24404898736823685,\n          0.30443385488725433\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"most\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18526886675016388,\n        \"min\": 0.0,\n        \"max\": 0.32089509027199203,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          0.32089509027199203\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"of\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2465265752622996,\n        \"min\": 0.0,\n        \"max\": 0.4880979747364737,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.4880979747364737,\n          0.30443385488725433\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"one\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16118633754253953,\n        \"min\": 0.0,\n        \"max\": 0.30443385488725433,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.24404898736823685,\n          0.30443385488725433\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"science\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2465265752622996,\n        \"min\": 0.0,\n        \"max\": 0.4880979747364737,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.4880979747364737,\n          0.30443385488725433\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scientists\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3133283451066585,\n        \"min\": 0.0,\n        \"max\": 0.5427006131762078,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.5427006131762078,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"the\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16118633754253953,\n        \"min\": 0.0,\n        \"max\": 0.30443385488725433,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.24404898736823685,\n          0.30443385488725433\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"this\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2311098107948397,\n        \"min\": 0.0,\n        \"max\": 0.40029393442429256,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.40029393442429256,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### X. Frequency of Words\n",
        "We can use FreqDist from Nltk package which can calculate the no. of times a particular word is appearing in the corpus"
      ],
      "metadata": {
        "id": "r5wVJ3F54Bmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "example_text = \"This is a sample text. We need to calculate the frequency of each word.\"\n",
        "\n",
        "tokens = word_tokenize(example_text)\n",
        "\n",
        "#Derive the frequency Distribution:\n",
        "freq_dist_tokens = FreqDist(tokens)\n",
        "\n",
        "for word, frequency in freq_dist_tokens.items():\n",
        "    print(f\"{word}:,{frequency}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FsZU2Le3_V0",
        "outputId": "be8ce1ce-cf8a-4c0d-e8c5-39fde3902fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This:,1\n",
            "is:,1\n",
            "a:,1\n",
            "sample:,1\n",
            "text:,1\n",
            ".:,2\n",
            "We:,1\n",
            "need:,1\n",
            "to:,1\n",
            "calculate:,1\n",
            "the:,1\n",
            "frequency:,1\n",
            "of:,1\n",
            "each:,1\n",
            "word:,1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq_dist_tokens"
      ],
      "metadata": {
        "id": "XyNnGSOR5Vuo",
        "outputId": "79a475a6-6036-4556-85cc-ec2e5ff0545f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'.': 2, 'This': 1, 'is': 1, 'a': 1, 'sample': 1, 'text': 1, 'We': 1, 'need': 1, 'to': 1, 'calculate': 1, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sGU_L9gL4nWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Useful Links:\n",
        "https://docs.python.org/3/library/re.html#regular-expression-syntax"
      ],
      "metadata": {
        "id": "usMrVQuu31BU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}